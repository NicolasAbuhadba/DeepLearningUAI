{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_augmentation-alumnos.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpUS3WwRdOeq",
        "colab_type": "text"
      },
      "source": [
        "# Laboratorio 5: Deep learning (Perros y gatos)\n",
        "\n",
        "Procedimiento:\n",
        "\n",
        "1.   Cargar la base de datos ([https://www.kaggle.com/chetankv/dogs-cats-images?](https://www.kaggle.com/chetankv/dogs-cats-images?))\n",
        "2.   Realizar las transformaciones\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9bEoPt953zN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocTPe2oRgHB3",
        "colab_type": "text"
      },
      "source": [
        "## 1. Cargar las librerías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UknSe3QigGdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E4cJ8wYf-G8",
        "colab_type": "text"
      },
      "source": [
        "## 2. Cargar imágenes\n",
        "\n",
        "Se cargan las imágenes utilizando la clase ImageFolder. La clase ImageForder etiqueta automáticamente las imágenes dada una ruta donde se encuentran los datos. Por ejemplo, si tengo el directorio raíz dataset/training_set. Debo dejar mis imágenes de cada clase en una carpeta diferente. Si tengo imágenes de gatos debo dejarlos en dataset/training_set/cats, si tengo imágenes de perros las debo dejar en dataset/training_set/dogs, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViYqZF2Wf9c1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import PIL\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((128,128)),  \n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.RandomVerticalFlip(p=0.6),\n",
        "    transforms.RandomHorizontalFlip(p=0.6),                              \n",
        "    transforms.RandomChoice([\n",
        "      transforms.RandomAffine(degrees=0, translate=(0.1, 0.1),\n",
        "                          scale=None, shear=None,\n",
        "                          resample=False, fillcolor=0),\n",
        "      transforms.ColorJitter(brightness=(1, 1.5),\n",
        "                            contrast=(0.3, 2),\n",
        "                            saturation=(0.1, 1),\n",
        "                            hue=(-0.3, 0.3)),\n",
        "      transforms.RandomRotation((-10, 10), resample=PIL.Image.BILINEAR)\n",
        "    ]),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "gatos_perros_dataset = datasets.ImageFolder(root='/content/drive/My Drive/D-UCN/Classes/TecnicasAvanzadasAprendizajeAutomatico/Laboratorios/Laboratorio05.2:DeepLearning/dataset/training_set',\n",
        "                                            transform=data_transform)\n",
        "\n",
        "print(gatos_perros_dataset)\n",
        "\n",
        "dataset_loader = torch.utils.data.DataLoader(gatos_perros_dataset,\n",
        "                                             batch_size=32,\n",
        "                                             shuffle=False,\n",
        "                                             num_workers=2)\n",
        "\n",
        "print(dataset_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12WdL18nhjbK",
        "colab_type": "text"
      },
      "source": [
        "## 3. Visualizo las imágenes cargadas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny7WjxC2c98h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.figure(num=None, figsize=(12, 8), dpi=80)\n",
        "\n",
        "def imshow(img):\n",
        "  np_img = img.numpy()\n",
        "  plt.imshow(np.transpose(np_img,(1, 2, 0)))\n",
        "\n",
        "# Obtener imagenes\n",
        "data_iter = iter(dataset_loader)\n",
        "images, labels = data_iter.next()\n",
        "\n",
        "# Mostrar imagenes\n",
        "imshow(torchvision.utils.make_grid(images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ9ZGWnAsc0p",
        "colab_type": "text"
      },
      "source": [
        "## 4. Separando la base de datos\n",
        "\n",
        "Para realizar el entrenamiento y pruebas se recomienda separar los datos en tres conjuntos:\n",
        "\n",
        "* **Conjunto de entrenamiento:** El modelo aprende de los ejemplos de este conjunto de datos. Se ajusta un parámetro a un clasificador.\n",
        "* **Conjunto de validación:** Los ejemplos en el conjunto de datos de validación se utilizan para ajustar los hiperparámetros, como la tasa de aprendizaje y las épocas. El objetivo de crear un conjunto de validación es evitar un sobreajuste grande del modelo. Es un punto de control para saber si el modelo se ajusta bien con el conjunto de datos de entrenamiento.\n",
        "* **Conjunto de pruebas:** Este conjunto de datos prueba la evolución final del modelo, midiendo qué tan bien aprendió y predijo el resultado deseado. Contiene datos invisibles de la vida real. Es un conjunto diferente al de entrenamiento y validación.\n",
        "\n",
        "Imagen: [https://i.imgur.com/DV80uhS.png](https://i.imgur.com/DV80uhS.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN-x-nvFtg2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transformaciones de la imagen\n",
        "import PIL\n",
        "\n",
        "#data_transform = transforms.Compose([\n",
        "#    transforms.Resize((32,32)),  \n",
        "#    transforms.RandomGrayscale(p=0.2),\n",
        "#    transforms.RandomVerticalFlip(p=0.2),\n",
        "#    transforms.RandomHorizontalFlip(p=0.2),                              \n",
        "#    transforms.ToTensor()\n",
        "#])\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((32,32)),  \n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.RandomVerticalFlip(p=0.6),\n",
        "    transforms.RandomHorizontalFlip(p=0.6),                              \n",
        "    transforms.RandomChoice([\n",
        "      transforms.RandomAffine(degrees=0, translate=(0.1, 0.1),\n",
        "                          scale=None, shear=None,\n",
        "                          resample=False, fillcolor=0),\n",
        "      transforms.ColorJitter(brightness=(1, 1.5),\n",
        "                            contrast=(0.3, 2),\n",
        "                            saturation=(0.1, 1),\n",
        "                            hue=(-0.3, 0.3)),\n",
        "      transforms.RandomRotation((-10, 10), resample=PIL.Image.BILINEAR)\n",
        "    ]),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "data_transform_test = transforms.Compose([\n",
        "    transforms.Resize((32,32)),                            \n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Cargar las imágenes\n",
        "gatos_perros_train = datasets.ImageFolder(root='/content/drive/My Drive/D-UCN/Classes/TecnicasAvanzadasAprendizajeAutomatico/Laboratorios/Laboratorio05.2:DeepLearning/dataset/training_set',\n",
        "                                          transform=data_transform)\n",
        "gatos_perros_valid = datasets.ImageFolder(root='/content/drive/My Drive/D-UCN/Classes/TecnicasAvanzadasAprendizajeAutomatico/Laboratorios/Laboratorio05.2:DeepLearning/dataset/valid_set',\n",
        "                                          transform=data_transform_test)\n",
        "gatos_perros_test = datasets.ImageFolder(root='/content/drive/My Drive/D-UCN/Classes/TecnicasAvanzadasAprendizajeAutomatico/Laboratorios/Laboratorio05.2:DeepLearning/dataset/test_set',\n",
        "                                          transform=data_transform_test)\n",
        "\n",
        "# Conjunto de entrenamiento\n",
        "train_loader = torch.utils.data.DataLoader(gatos_perros_train,\n",
        "                                           batch_size=32,\n",
        "                                           shuffle=True,\n",
        "                                           num_workers=2)\n",
        "\n",
        "# Conjunto de validacion\n",
        "valid_loader = torch.utils.data.DataLoader(gatos_perros_valid,\n",
        "                                           batch_size=32,\n",
        "                                           shuffle=False,\n",
        "                                           num_workers=2)\n",
        "\n",
        "# Conjunto de pruebas\n",
        "test_loader = torch.utils.data.DataLoader(gatos_perros_test,\n",
        "                                           batch_size=32,\n",
        "                                           shuffle=False,\n",
        "                                           num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sveSe-qCdBzx",
        "colab_type": "text"
      },
      "source": [
        "### Revisamos las imagenes de las nuevas cargas\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgR6XHBudLIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(num=None, figsize=(12, 8), dpi=80)\n",
        "\n",
        "# Obtener imagenes\n",
        "data_iter = iter(test_loader)\n",
        "images, labels = data_iter.next()\n",
        "\n",
        "# Mostrar imagenes\n",
        "imshow(torchvision.utils.make_grid(images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qc994ub9uREd",
        "colab_type": "text"
      },
      "source": [
        "## 5. El modelo\n",
        "\n",
        "Construimos un modelo con dos capas convolucionales, un dropout y dos capas completamente conectadas para la clasificación.\n",
        "\n",
        "* Imagen red: [https://i.imgur.com/wiP9IwZ.png](https://i.imgur.com/wiP9IwZ.png)\n",
        "* Imagen Conv: https://i.imgur.com/E9GGJMJ.gif\n",
        "* Imagen Pool: https://i.imgur.com/kSwID7J.png"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry6QGZ4duYLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn # Módulo están los modelos de red\n",
        "import torch.nn.functional as F # Módulo donde están las funciones de activación\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=3)\n",
        "    self.conv2 = nn.Conv2d(10, 20, kernel_size=3)\n",
        "    self.conv2_drop = nn.Dropout2d()\n",
        "    self.fc1 = nn.Linear(720, 1024)\n",
        "    self.fc2 = nn.Linear(1024, 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "    x = x.view(x.shape[0], -1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.dropout(x, training=self.training)\n",
        "    x = self.fc2(x)\n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Pq3a1-seC27",
        "colab_type": "text"
      },
      "source": [
        "### Creamos el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfCJxfVyeGF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CNN()\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OE9DpmgebP2",
        "colab_type": "text"
      },
      "source": [
        "## 6. Optimización\n",
        "\n",
        "Seleccionamos cualquier algoritmo optimizador disponible en el paquete `torch.optim`. En general, los optimizadores son moficaciones del descenso del gradiente. Cambiando los parámetros del modelo, como los pesos, y añadiendo sesgo, el modelo puede ser optimizado. La **tasa de aprendizaje** decidirá cuán grandes deben ser los pasos para cambiar los parámetros.\n",
        "\n",
        "* Calcular lo que un pequeño cambio en cada peso haría a la función de pérdida (seleccionando la dirección para alcanzar los mínimos).\n",
        "* Ajustar cada peso en función de su gradiente (es decir, dar un pequeño paso en la dirección determinada).\n",
        "* Continúe haciendo los pasos 1 y 2 hasta que la función de pérdida sea lo más baja posible.\n",
        "\n",
        "Aquí, la estimación del momento adaptativo (*adaptive moment estimation* - Adam) se utiliza como un optimizador. Es una mezcla de **RMSprop** y **descenso de gradiente estocástico**.\n",
        "\n",
        "### Configuración de Hyperparámetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdMQvmHNgF9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 500\n",
        "num_classes = 2\n",
        "learning_rate = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_--K5URFhI6w",
        "colab_type": "text"
      },
      "source": [
        "### Configuración del dispositivo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLHbjrZFgIAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7xEUGTKhQr_",
        "colab_type": "text"
      },
      "source": [
        "### Optimizador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAUo9F4AgHtB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMy41FuKhi53",
        "colab_type": "text"
      },
      "source": [
        "## 7. Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn5lAw3Zh8kd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Guardar las perdidas\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "  ## Calcular el loss por cada iteracion\n",
        "  train_loss = 0.0\n",
        "  valid_loss = 0.0\n",
        "  # Entrenar el model\n",
        "  model.train()\n",
        "  for data, target in train_loader:\n",
        "\n",
        "    # Mover a GPU\n",
        "    data = data.to(device)\n",
        "    target = target.to(device)\n",
        "\n",
        "    # Limpiar gradientes\n",
        "    optimizer.zero_grad()\n",
        "    # Prediccion\n",
        "    output = model(data)\n",
        "    # Medir el error\n",
        "    loss = criterion(output, target)\n",
        "    # Calcular gradientes\n",
        "    loss.backward()\n",
        "    # Actualizamos los pesos (Adam)\n",
        "    optimizer.step()\n",
        "    # Historia de la perdida\n",
        "    train_loss += loss.item() * data.size(0)\n",
        "  \n",
        "  # Validar modelo (No calcula graientes, no actualizo pesos, no dropout)\n",
        "  model.eval()\n",
        "  for data, target in valid_loader:\n",
        "     # Mover a GPU\n",
        "    data = data.to(device)\n",
        "    target = target.to(device) \n",
        "\n",
        "    # Prediccion para el conjunto de validacion\n",
        "    output = model(data)\n",
        "\n",
        "    loss = criterion(output, target)  \n",
        "\n",
        "    valid_loss += loss.item() * data.size(0)\n",
        "\n",
        "  # Calculo el promedio de las perdidas\n",
        "  train_loss = train_loss/len(train_loader.sampler)\n",
        "  valid_loss = valid_loss/len(valid_loader.sampler)\n",
        "\n",
        "  train_losses.append(train_loss)\n",
        "  valid_losses.append(valid_loss)\n",
        "\n",
        "  # Imprimimos las perdidas\n",
        "  print('Epoch: {} \\tPerdida de entrenamiento: {:.6f} \\tPerdida de Validacion: {:.6f}'.format(epoch, train_loss, valid_loss))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYWlCVMUh-D6",
        "colab_type": "text"
      },
      "source": [
        "## 8. Pruebas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGHRkuVpiI8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test-the-model\n",
        "model.eval()  # it-disables-dropout\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "          \n",
        "    print('Test Accuracy of the model: {} %'.format(100 * correct / total))\n",
        "\n",
        "# Save \n",
        "torch.save(model.state_dict(), 'model.ckpt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9OXbPI1iOid",
        "colab_type": "text"
      },
      "source": [
        "9. Graficamos los resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FohlEiWNiNh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(valid_losses, label='Validation loss')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(frameon=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}